{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[Reference](https://jscriptcoder.github.io/date-translator/Machine%20Translation%20with%20Attention%20model.html)"
      ],
      "metadata": {
        "id": "ZsGBya10WIw6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing stuff**"
      ],
      "metadata": {
        "id": "PmzrC7BhPmsB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8kuwQSdMu4M"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, Multiply\n",
        "from keras.layers import RepeatVector, Dense, Activation, Lambda\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import load_model, Model\n",
        "import keras.backend as K\n",
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from babel.dates import format_date\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwa6TLqcOcjY",
        "outputId": "cd1d4bf1-912e-45c2-9031-20266b611bdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reading stuff**"
      ],
      "metadata": {
        "id": "X9KyHioEWATS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(r\"/content/drive/MyDrive/Data/DLNLP/Assignment4aDataset.txt\",names=['human_date','machine_date'],sep=',')\n",
        "df = df.sample(frac=1) #Shuffeling the rows of dataframe\n",
        "df.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3o0xmGDeRc5j",
        "outputId": "86f6a9db-67a7-4c8b-e3d6-78ca60eb6574"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40000"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making vocab-int mapping for machine and human dates:"
      ],
      "metadata": {
        "id": "ZP8v5hawWFEA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(df):\n",
        "    human_vocab = set()\n",
        "    machine_vocab = set()\n",
        "    dataset = []\n",
        "    \n",
        "    for index, row in df.iterrows():\n",
        "        h = row['human_date']\n",
        "        m = row['machine_date']\n",
        "        dataset.append((h, m))\n",
        "        human_vocab.update(tuple(h))\n",
        "        machine_vocab.update(tuple(m))\n",
        "    \n",
        "    # We also add two special chars, <unk> for unknown characters, and <pad> to add padding at the end\n",
        "    human = dict(zip(sorted(human_vocab) + ['<unk>', '<pad>'], list(range(len(human_vocab) + 2))))\n",
        "    inv_machine = dict(enumerate(sorted(machine_vocab)))\n",
        "    machine = {v: k for k, v in inv_machine.items()}\n",
        " \n",
        "    return dataset, human, machine, inv_machine"
      ],
      "metadata": {
        "id": "Boux6-nzRMOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset, human_vocab, machine_vocab, inv_machine_vocab = create_dataset(df)"
      ],
      "metadata": {
        "id": "7xLLctH-Vdvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb1NPEzAVj7v",
        "outputId": "1750e7e1-3beb-4b7f-a5e4-836346399e34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(\"'26 october 1662'\", \" '1662-10-26'\"),\n",
              " (\"'29 september 1533'\", \" '1533-09-29'\"),\n",
              " (\"'12 apr 1955'\", \" '1955-04-12'\"),\n",
              " (\"'15 january 1707'\", \" '1707-01-15'\"),\n",
              " (\"'1556 14 apr'\", \" '1556-04-14'\"),\n",
              " (\"'september 25 1731'\", \" '1731-09-25'\"),\n",
              " (\"'dec 5 1757'\", \" '1757-12-05'\"),\n",
              " (\"'24 january 1793'\", \" '1793-01-24'\"),\n",
              " (\"'tuesday august 21 1827'\", \" '1827-08-21'\"),\n",
              " (\"'30 september 2043'\", \" '2043-09-30'\")]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "human_vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RD-AQd7iVnoc",
        "outputId": "7964a91f-c9b1-431c-ec7d-7213e0ecb851"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{' ': 0,\n",
              " \"'\": 1,\n",
              " '/': 2,\n",
              " '0': 3,\n",
              " '1': 4,\n",
              " '2': 5,\n",
              " '3': 6,\n",
              " '4': 7,\n",
              " '5': 8,\n",
              " '6': 9,\n",
              " '7': 10,\n",
              " '8': 11,\n",
              " '9': 12,\n",
              " 'a': 13,\n",
              " 'b': 14,\n",
              " 'c': 15,\n",
              " 'd': 16,\n",
              " 'e': 17,\n",
              " 'f': 18,\n",
              " 'g': 19,\n",
              " 'h': 20,\n",
              " 'i': 21,\n",
              " 'j': 22,\n",
              " 'l': 23,\n",
              " 'm': 24,\n",
              " 'n': 25,\n",
              " 'o': 26,\n",
              " 'p': 27,\n",
              " 'r': 28,\n",
              " 's': 29,\n",
              " 't': 30,\n",
              " 'u': 31,\n",
              " 'v': 32,\n",
              " 'w': 33,\n",
              " 'y': 34,\n",
              " '<unk>': 35,\n",
              " '<pad>': 36}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "machine_vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyMHyOQcVr2y",
        "outputId": "40b776cd-e8c5-4821-e89c-4667dd08a33c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{' ': 0,\n",
              " \"'\": 1,\n",
              " '-': 2,\n",
              " '0': 3,\n",
              " '1': 4,\n",
              " '2': 5,\n",
              " '3': 6,\n",
              " '4': 7,\n",
              " '5': 8,\n",
              " '6': 9,\n",
              " '7': 10,\n",
              " '8': 11,\n",
              " '9': 12}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inv_machine_vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vwRw0w8Vu4A",
        "outputId": "fc94e93c-868f-4bb3-899d-315b5739dd79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: ' ',\n",
              " 1: \"'\",\n",
              " 2: '-',\n",
              " 3: '0',\n",
              " 4: '1',\n",
              " 5: '2',\n",
              " 6: '3',\n",
              " 7: '4',\n",
              " 8: '5',\n",
              " 9: '6',\n",
              " 10: '7',\n",
              " 11: '8',\n",
              " 12: '9'}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing**"
      ],
      "metadata": {
        "id": "JZQO1yEvV74o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def string_to_int(string, length, vocab):\n",
        "    string = string.lower()\n",
        "    string = string.replace(',','')\n",
        "    string = string.replace('\\'','')\n",
        "    \n",
        "    if len(string) > length:\n",
        "        string = string[:length]\n",
        "        \n",
        "    rep = list(map(lambda x: vocab.get(x, '<unk>'), string))\n",
        "    \n",
        "    if len(string) < length:\n",
        "        rep += [vocab['<pad>']] * (length - len(string))\n",
        "    \n",
        "    return rep\n",
        "\n",
        "def preprocess_data(dataset, human_vocab, machine_vocab, Tx, Ty):\n",
        "    X, Y = zip(*dataset)\n",
        "    \n",
        "    X = np.array([string_to_int(i, Tx, human_vocab) for i in X])\n",
        "    Y = [string_to_int(t, Ty, machine_vocab) for t in Y]\n",
        "    \n",
        "    Xoh = np.array(list(map(lambda x: to_categorical(x, num_classes=len(human_vocab)), X)))\n",
        "    Yoh = np.array(list(map(lambda x: to_categorical(x, num_classes=len(machine_vocab)), Y)))\n",
        "\n",
        "    return X, np.array(Y), Xoh, Yoh"
      ],
      "metadata": {
        "id": "H2O6ynkBV7rk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "string_to_int('September 10, 1978', 30, human_vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNqn7RZzWmpZ",
        "outputId": "4e6805af-4cd2-439a-8a72-18966465a355"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[29,\n",
              " 17,\n",
              " 27,\n",
              " 30,\n",
              " 17,\n",
              " 24,\n",
              " 14,\n",
              " 17,\n",
              " 28,\n",
              " 0,\n",
              " 4,\n",
              " 3,\n",
              " 0,\n",
              " 4,\n",
              " 12,\n",
              " 10,\n",
              " 11,\n",
              " 36,\n",
              " 36,\n",
              " 36,\n",
              " 36,\n",
              " 36,\n",
              " 36,\n",
              " 36,\n",
              " 36,\n",
              " 36,\n",
              " 36,\n",
              " 36,\n",
              " 36,\n",
              " 36]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Tx = 30\n",
        "Ty = 10\n",
        "X, Y, Xoh, Yoh = preprocess_data(dataset, human_vocab, machine_vocab, Tx, Ty)\n",
        "\n",
        "print(\"X.shape:\", X.shape)\n",
        "print(\"Y.shape:\", Y.shape)\n",
        "print(\"Xoh.shape:\", Xoh.shape)\n",
        "print(\"Yoh.shape:\", Yoh.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLS1hPwZWsbA",
        "outputId": "8094213e-5cc2-4125-c7f3-7c586d1bd62d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X.shape: (40000, 30)\n",
            "Y.shape: (40000, 10)\n",
            "Xoh.shape: (40000, 30, 37)\n",
            "Yoh.shape: (40000, 10, 13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index = 0\n",
        "print(\"Source date:\", dataset[index][0])\n",
        "print(\"Target date:\", dataset[index][1])\n",
        "print()\n",
        "print(\"Source after preprocessing (indices):\", X[index])\n",
        "print(\"Target after preprocessing (indices):\", Y[index])\n",
        "print()\n",
        "print(\"Source after preprocessing (one-hot):\", Xoh[index])\n",
        "print(\"Target after preprocessing (one-hot):\", Yoh[index])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqOOV7-oWwhY",
        "outputId": "b59782d7-5bb9-4b9a-8916-ea7104adddb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source date: '26 october 1662'\n",
            "Target date:  '1662-10-26'\n",
            "\n",
            "Source after preprocessing (indices): [ 1  5  9  0 26 15 30 26 14 17 28  0  4  9  9  5  1 36 36 36 36 36 36 36\n",
            " 36 36 36 36 36 36]\n",
            "Target after preprocessing (indices): [0 1 4 9 9 5 2 4 3 2]\n",
            "\n",
            "Source after preprocessing (one-hot): [[0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 1.]\n",
            " [0. 0. 0. ... 0. 0. 1.]\n",
            " [0. 0. 0. ... 0. 0. 1.]]\n",
            "Target after preprocessing (one-hot): [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define Model**\n",
        "\n"
      ],
      "metadata": {
        "id": "lSATdmDaW0tc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "repeator = RepeatVector(Tx)\n",
        "concatenator = Concatenate(axis=-1)\n",
        "densor1 = Dense(10, activation = \"tanh\")\n",
        "densor2 = Dense(1, activation = \"relu\")\n",
        "activator = Activation('softmax', name='attention_vec')\n",
        "dotor = Dot(axes = 1)"
      ],
      "metadata": {
        "id": "HWQiLqkMWzoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def one_step_attention(a, s_prev):\n",
        "    s_prev = repeator(s_prev)\n",
        "    concat = concatenator([a, s_prev])\n",
        "    e = densor1(concat)\n",
        "    energies = densor2(e)\n",
        "    alphas = activator(energies)\n",
        "    context = dotor([alphas, a])\n",
        "    return context, alphas         #here"
      ],
      "metadata": {
        "id": "-q_eJs2oW8ju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_a = 32\n",
        "n_s = 64\n",
        "val_size = 0.1\n",
        "post_activation_LSTM_cell = LSTM(n_s, return_state = True, name='final_LSTM')\n",
        "output_layer = Dense(len(machine_vocab), activation='softmax')"
      ],
      "metadata": {
        "id": "WGRZR2RDW-46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model(Tx, Ty, n_a, n_s, human_vocab_size, machine_vocab_size, gib_attention=False):\n",
        "    X = Input(shape=(Tx, human_vocab_size))\n",
        "    s0 = Input(shape=(n_s,), name='s0')\n",
        "    c0 = Input(shape=(n_s,), name='c0')\n",
        "    s = s0\n",
        "    c = c0\n",
        "    \n",
        "    outputs1 = []\n",
        "    outputs2 = []\n",
        "    \n",
        "    a = Bidirectional(LSTM(n_a, return_sequences = True),name='bi_LSTM')(X)\n",
        "    \n",
        "    for t in range(Ty):\n",
        "        context, alphas = one_step_attention(a, s)         #here\n",
        "        s, _, c = post_activation_LSTM_cell(context, initial_state=[s, c])\n",
        "        out = output_layer(s)\n",
        "        outputs1.append(out)\n",
        "        # outputs2.append(alphas.reshape) #(Ty=13,(none,30,1))\n",
        "    # model = Model([X, s0, c0], outputs=[outputs1,outputs2]) #,outputs2])\n",
        "    # if gib_attention == False:\n",
        "\n",
        "    model = Model([X, s0, c0], outputs1) #,outputs2])\n",
        "    # else:\n",
        "    #   model = Model([X, s0, c0], outputs2)\n",
        "    # final_alphas= model.get_layer('attention_vec').output     #here\n",
        "    return model #, final_alphas          #here"
      ],
      "metadata": {
        "id": "qUc6eBOKXBD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write custome class for overall accuracy "
      ],
      "metadata": {
        "id": "yfmoko19bLlQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zvc1NRVnTjwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mod = model(Tx, Ty, n_a, n_s, len(human_vocab), len(machine_vocab), gib_attention=False)"
      ],
      "metadata": {
        "id": "7BCPJwWVXD_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = Model(inputs=model.input, outputs=[model.output, model.get_layer('attention_vec').output])\n",
        "# attention_map = plot_attention_map(model, human_vocab, inv_machine_vocab, \"Tuesday 09 Oct 1993\", num = 7, n_s = 64)"
      ],
      "metadata": {
        "id": "BwoknoCbjsK0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "d608c071-8585-41c3-c970-6a0f8414e9b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-d669295e89ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'attention_vec'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# attention_map = plot_attention_map(model, human_vocab, inv_machine_vocab, \"Tuesday 09 Oct 1993\", num = 7, n_s = 64)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'input'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mod.summary()"
      ],
      "metadata": {
        "id": "0V_abfJFXF2I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bb6b303-f688-4e31-b2b3-eb166a56e0de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 30, 37)]     0           []                               \n",
            "                                                                                                  \n",
            " s0 (InputLayer)                [(None, 64)]         0           []                               \n",
            "                                                                                                  \n",
            " bi_output (Bidirectional)      (None, 30, 64)       17920       ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " repeat_vector (RepeatVector)   (None, 30, 64)       0           ['s0[0][0]',                     \n",
            "                                                                  'lstm[10][0]',                  \n",
            "                                                                  'lstm[11][0]',                  \n",
            "                                                                  'lstm[12][0]',                  \n",
            "                                                                  'lstm[13][0]',                  \n",
            "                                                                  'lstm[14][0]',                  \n",
            "                                                                  'lstm[15][0]',                  \n",
            "                                                                  'lstm[16][0]',                  \n",
            "                                                                  'lstm[17][0]',                  \n",
            "                                                                  'lstm[18][0]']                  \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 30, 128)      0           ['bi_output[0][0]',              \n",
            "                                                                  'repeat_vector[10][0]',         \n",
            "                                                                  'bi_output[0][0]',              \n",
            "                                                                  'repeat_vector[11][0]',         \n",
            "                                                                  'bi_output[0][0]',              \n",
            "                                                                  'repeat_vector[12][0]',         \n",
            "                                                                  'bi_output[0][0]',              \n",
            "                                                                  'repeat_vector[13][0]',         \n",
            "                                                                  'bi_output[0][0]',              \n",
            "                                                                  'repeat_vector[14][0]',         \n",
            "                                                                  'bi_output[0][0]',              \n",
            "                                                                  'repeat_vector[15][0]',         \n",
            "                                                                  'bi_output[0][0]',              \n",
            "                                                                  'repeat_vector[16][0]',         \n",
            "                                                                  'bi_output[0][0]',              \n",
            "                                                                  'repeat_vector[17][0]',         \n",
            "                                                                  'bi_output[0][0]',              \n",
            "                                                                  'repeat_vector[18][0]',         \n",
            "                                                                  'bi_output[0][0]',              \n",
            "                                                                  'repeat_vector[19][0]']         \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 30, 10)       1290        ['concatenate[10][0]',           \n",
            "                                                                  'concatenate[11][0]',           \n",
            "                                                                  'concatenate[12][0]',           \n",
            "                                                                  'concatenate[13][0]',           \n",
            "                                                                  'concatenate[14][0]',           \n",
            "                                                                  'concatenate[15][0]',           \n",
            "                                                                  'concatenate[16][0]',           \n",
            "                                                                  'concatenate[17][0]',           \n",
            "                                                                  'concatenate[18][0]',           \n",
            "                                                                  'concatenate[19][0]']           \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 30, 1)        11          ['dense[10][0]',                 \n",
            "                                                                  'dense[11][0]',                 \n",
            "                                                                  'dense[12][0]',                 \n",
            "                                                                  'dense[13][0]',                 \n",
            "                                                                  'dense[14][0]',                 \n",
            "                                                                  'dense[15][0]',                 \n",
            "                                                                  'dense[16][0]',                 \n",
            "                                                                  'dense[17][0]',                 \n",
            "                                                                  'dense[18][0]',                 \n",
            "                                                                  'dense[19][0]']                 \n",
            "                                                                                                  \n",
            " attention_vec (Activation)     (None, 30, 1)        0           ['dense_1[10][0]',               \n",
            "                                                                  'dense_1[11][0]',               \n",
            "                                                                  'dense_1[12][0]',               \n",
            "                                                                  'dense_1[13][0]',               \n",
            "                                                                  'dense_1[14][0]',               \n",
            "                                                                  'dense_1[15][0]',               \n",
            "                                                                  'dense_1[16][0]',               \n",
            "                                                                  'dense_1[17][0]',               \n",
            "                                                                  'dense_1[18][0]',               \n",
            "                                                                  'dense_1[19][0]']               \n",
            "                                                                                                  \n",
            " dot (Dot)                      (None, 1, 64)        0           ['attention_vec[10][0]',         \n",
            "                                                                  'bi_output[0][0]',              \n",
            "                                                                  'attention_vec[11][0]',         \n",
            "                                                                  'bi_output[0][0]',              \n",
            "                                                                  'attention_vec[12][0]',         \n",
            "                                                                  'bi_output[0][0]',              \n",
            "                                                                  'attention_vec[13][0]',         \n",
            "                                                                  'bi_output[0][0]',              \n",
            "                                                                  'attention_vec[14][0]',         \n",
            "                                                                  'bi_output[0][0]',              \n",
            "                                                                  'attention_vec[15][0]',         \n",
            "                                                                  'bi_output[0][0]',              \n",
            "                                                                  'attention_vec[16][0]',         \n",
            "                                                                  'bi_output[0][0]',              \n",
            "                                                                  'attention_vec[17][0]',         \n",
            "                                                                  'bi_output[0][0]',              \n",
            "                                                                  'attention_vec[18][0]',         \n",
            "                                                                  'bi_output[0][0]',              \n",
            "                                                                  'attention_vec[19][0]',         \n",
            "                                                                  'bi_output[0][0]']              \n",
            "                                                                                                  \n",
            " c0 (InputLayer)                [(None, 64)]         0           []                               \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, 64),         33024       ['dot[10][0]',                   \n",
            "                                 (None, 64),                      's0[0][0]',                     \n",
            "                                 (None, 64)]                      'c0[0][0]',                     \n",
            "                                                                  'dot[11][0]',                   \n",
            "                                                                  'lstm[10][0]',                  \n",
            "                                                                  'lstm[10][2]',                  \n",
            "                                                                  'dot[12][0]',                   \n",
            "                                                                  'lstm[11][0]',                  \n",
            "                                                                  'lstm[11][2]',                  \n",
            "                                                                  'dot[13][0]',                   \n",
            "                                                                  'lstm[12][0]',                  \n",
            "                                                                  'lstm[12][2]',                  \n",
            "                                                                  'dot[14][0]',                   \n",
            "                                                                  'lstm[13][0]',                  \n",
            "                                                                  'lstm[13][2]',                  \n",
            "                                                                  'dot[15][0]',                   \n",
            "                                                                  'lstm[14][0]',                  \n",
            "                                                                  'lstm[14][2]',                  \n",
            "                                                                  'dot[16][0]',                   \n",
            "                                                                  'lstm[15][0]',                  \n",
            "                                                                  'lstm[15][2]',                  \n",
            "                                                                  'dot[17][0]',                   \n",
            "                                                                  'lstm[16][0]',                  \n",
            "                                                                  'lstm[16][2]',                  \n",
            "                                                                  'dot[18][0]',                   \n",
            "                                                                  'lstm[17][0]',                  \n",
            "                                                                  'lstm[17][2]',                  \n",
            "                                                                  'dot[19][0]',                   \n",
            "                                                                  'lstm[18][0]',                  \n",
            "                                                                  'lstm[18][2]']                  \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 13)           845         ['lstm[10][0]',                  \n",
            "                                                                  'lstm[11][0]',                  \n",
            "                                                                  'lstm[12][0]',                  \n",
            "                                                                  'lstm[13][0]',                  \n",
            "                                                                  'lstm[14][0]',                  \n",
            "                                                                  'lstm[15][0]',                  \n",
            "                                                                  'lstm[16][0]',                  \n",
            "                                                                  'lstm[17][0]',                  \n",
            "                                                                  'lstm[18][0]',                  \n",
            "                                                                  'lstm[19][0]']                  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 53,090\n",
            "Trainable params: 53,090\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train Model**"
      ],
      "metadata": {
        "id": "nxnxGh9tXOQl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mod1 = model(Tx, Ty, n_a, n_s, len(human_vocab), len(machine_vocab), gib_attention=True)\n",
        "# mod1.summary()"
      ],
      "metadata": {
        "id": "6fh876CLQwue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt = Adam(learning_rate=0.005, beta_1=0.9, beta_2=0.999, decay=0.01)\n",
        "mod.compile(optimizer=opt, loss=['categorical_crossentropy'], metrics=['accuracy','overall_accuray'])\n",
        "# mod1.compile(optimizer=opt, loss=['categorical_crossentropy'], metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "ncyQVEMfXKPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s0 = np.zeros((df.shape[0], n_s))\n",
        "c0 = np.zeros((df.shape[0], n_s))\n",
        "outputs = list(Yoh.swapaxes(0,1))\n",
        "# op=np.array(outputs)\n",
        "# op.shape\n",
        "# dummy = np.zeros((13,None,30,1))"
      ],
      "metadata": {
        "id": "iFJimk29XpKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# b = "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nZNhnwIoE5v",
        "outputId": "a963ab1f-f406-49f4-d4c6-3e64684f3198"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 40000, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mod.fit([Xoh, s0, c0], outputs, epochs=1, batch_size=100, validation_split = 0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 831
        },
        "id": "EWJmr9W9X_ag",
        "outputId": "67f20db2-1a1c-4c49-b28d-f6c59be467e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-d2219f2f1141>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mXoh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 864, in train_step\n        return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 957, in compute_metrics\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py\", line 438, in update_state\n        self.build(y_pred, y_true)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py\", line 359, in build\n        self._metrics, y_true, y_pred)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py\", line 484, in _get_metric_objects\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py\", line 484, in <listcomp>\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py\", line 503, in _get_metric_object\n        metric_obj = metrics_mod.get(metric)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/metrics.py\", line 4262, in get\n        return deserialize(str(identifier))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/metrics.py\", line 4222, in deserialize\n        printable_module_name='metric function')\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py\", line 710, in deserialize_keras_object\n        f'Unknown {printable_module_name}: {object_name}. Please ensure '\n\n    ValueError: Unknown metric function: overall_accuray. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_alphas= mod.get_layer('attention_vec').output"
      ],
      "metadata": {
        "id": "LLzzyOeqfy2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(final_alphas.numpy())\n",
        "#  output_before_att = new_model.predict(x_test_sample) #extract layer output"
      ],
      "metadata": {
        "id": "crJbMiGzf2Ih",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "943d4433-334a-4424-baf7-be779c01bfe8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-fb4a4a59a11d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_alphas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#  output_before_att = new_model.predict(x_test_sample) #extract layer output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'KerasTensor' object has no attribute 'numpy'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# output_before_att = new_model.predict(x_test_sample) #extract layer output"
      ],
      "metadata": {
        "id": "aY6lp7xWLVWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EXAMPLES = ['3 May 1979', '5 April 09', '21th of August 2016', 'Tue 10 Jul 2007', 'Saturday May 9 2018', 'March 3 2001', 'March 3rd 2001', '1 March 2001']\n",
        "for example in EXAMPLES:\n",
        "    \n",
        "    source = string_to_int(example, Tx, human_vocab)\n",
        "    source = np.array(list(map(lambda x: to_categorical(x, num_classes=len(human_vocab)), source)))\n",
        "    source = source.reshape((1, ) + source.shape)\n",
        "    prediction = mod.predict([source, s0, c0])\n",
        "    prediction = np.argmax(prediction, axis = -1)\n",
        "    output = [inv_machine_vocab[int(i)] for i in prediction]\n",
        "    \n",
        "    print(\"source:\", example)\n",
        "    print(\"output:\", ''.join(output))"
      ],
      "metadata": {
        "id": "Q8swFi_-T4kV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "7c2a4e5a-0266-4fe0-aa97-0ee2e7d807df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-a96e0a0f2f6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhuman_vocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0msource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minv_machine_vocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_check_data_cardinality\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1651\u001b[0m                            for i in tf.nest.flatten(single_data)))\n\u001b[1;32m   1652\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"Make sure all arrays contain the same number of samples.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1653\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 1, 40000, 40000\nMake sure all arrays contain the same number of samples."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mod.save('/content/drive/MyDrive/Data/DLNLP/dates_model.h5')\n",
        "# !tensorflowjs_converter --input_format keras dates_model.h5 tfjsmodel"
      ],
      "metadata": {
        "id": "js_tw1arYHCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a = tf.keras.utils.to_categorical([0, 1, 2, 3], num_classes=4)\n",
        "# print(a)"
      ],
      "metadata": {
        "id": "XBI_hu9BxQk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://jacobgil.github.io/deeplearning/class-activation-maps"
      ],
      "metadata": {
        "id": "BzEoWq8w9Ce-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mod.load_weights('/content/drive/MyDrive/Data/DLNLP/dates_model.h5')"
      ],
      "metadata": {
        "id": "ebj7XzAT5F0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model('/content/drive/MyDrive/Data/DLNLP/dates_model.h5')\n",
        "# model.summary()\n",
        "model = Model(inputs=model.input, outputs=[model.output, model.get_layer('attention_vec').output])"
      ],
      "metadata": {
        "id": "kNO77LeokXEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = Xoh[0:1]\n",
        "# input.shape[0]\n",
        "s0 = np.zeros((input.shape[0], n_s))\n",
        "c0 = np.zeros((input.shape[0], n_s))\n",
        "new_model = Model(inputs=mod.input, outputs=mod.get_layer('attention_vec').output)\n",
        "output_before_att = new_model.predict([input, s0, c0]) #extract layer output"
      ],
      "metadata": {
        "id": "FYv3RJKzqpJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# b = mod1.predict([input, s0, c0])\n",
        "# b = mod.predict([input, s0, c0])\n",
        "model = Model(inputs=mod.input, outputs=[mod.output, mod.get_layer('attention_vec').output])\n",
        "ouputs,alphas1 = model.predict([input, s0, c0])\n",
        "model_outputs = outputs\n",
        "attention_outputs = alphas1\n",
        "print(attention_outputs)\n",
        "# b=np.array(b)\n",
        "# print(b.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "id": "Hl4HanQBK_4l",
        "outputId": "12631a1b-088d-4df7-84a0-a504c79b2711"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-d05a85e242e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# b = mod1.predict([input, s0, c0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# b = mod.predict([input, s0, c0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'attention_vec'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mouputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malphas1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    627\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, outputs, name, trainable, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m                   for t in tf.nest.flatten(inputs)]):\n\u001b[1;32m    145\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctional_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone_graph_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_automatic_dependency_tracking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    627\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[0;34m(self, inputs, outputs)\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;31m# Keep track of the network's nodes and layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     nodes, nodes_by_depth, layers, _ = _map_graph_network(\n\u001b[0;32m--> 230\u001b[0;31m         self.inputs, self.outputs)\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_network_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodes_by_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes_by_depth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m_map_graph_network\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcomputable_tensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m             raise ValueError(\n\u001b[0;32m-> 1037\u001b[0;31m                 \u001b[0;34mf'Graph disconnected: cannot obtain value for tensor {x} '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m                 \u001b[0;34mf'at layer \"{layer.name}\". The following previous layers '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m                 f'were accessed without issue: {layers_with_complete_input}')\n",
            "\u001b[0;31mValueError\u001b[0m: Graph disconnected: cannot obtain value for tensor KerasTensor(type_spec=TensorSpec(shape=(None, 30, 37), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\") at layer \"bidirectional\". The following previous layers were accessed without issue: ['bidirectional_2', 'repeat_vector', 'concatenate', 'dense', 'dense_1', 'attention_vec', 'dot', 'lstm', 'repeat_vector', 'concatenate', 'dense', 'dense_1', 'attention_vec', 'dot', 'lstm', 'repeat_vector', 'concatenate', 'dense', 'dense_1', 'attention_vec', 'dot', 'lstm', 'repeat_vector', 'concatenate', 'dense', 'dense_1', 'attention_vec', 'dot', 'lstm', 'repeat_vector', 'concatenate', 'dense', 'dense_1', 'attention_vec', 'dot', 'lstm', 'repeat_vector', 'concatenate', 'dense', 'dense_1', 'attention_vec', 'dot', 'lstm', 'repeat_vector', 'concatenate', 'dense', 'dense_1', 'attention_vec', 'dot', 'lstm', 'repeat_vector', 'concatenate', 'dense', 'dense_1', 'attention_vec', 'dot', 'lstm', 'repeat_vector', 'concatenate', 'dense', 'dense_1', 'attention_vec', 'dot', 'lstm', 'repeat_vector', 'concatenate', 'dense']"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def visualize_class_activation_map(model_path, input):\n",
        "#         model = load_model(model_path)\n",
        "#         model = Model(inputs=model.input, outputs=[model.output, model.get_layer('attention_vec').output])\n",
        "#         ouputs,alphas1 = model.predict(input)\n",
        "#         model_outputs = outputs\n",
        "#         attention_outputs = alphas1\n",
        "#         print(attention_outputs)"
      ],
      "metadata": {
        "id": "MmpaxuuU9Thv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b = mod1.predict([input, s0, c0])"
      ],
      "metadata": {
        "id": "Fs_TXdqhRVVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b=np.array(b)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JG4-4NX46pys",
        "outputId": "f6548e0e-f329-459f-dadb-2df358ae5ba1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[[1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]]]\n",
            "\n",
            "\n",
            " [[[1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]]]\n",
            "\n",
            "\n",
            " [[[1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]]]\n",
            "\n",
            "\n",
            " [[[1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]]]\n",
            "\n",
            "\n",
            " [[[1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]]]\n",
            "\n",
            "\n",
            " [[[1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]]]\n",
            "\n",
            "\n",
            " [[[1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]]]\n",
            "\n",
            "\n",
            " [[[1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]]]\n",
            "\n",
            "\n",
            " [[[1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]]]\n",
            "\n",
            "\n",
            " [[[1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [1.]]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Xoh[0].shape"
      ],
      "metadata": {
        "id": "I3SsdW5QSWoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For making attention map\n",
        "example = '1 March 2001'\n",
        "# source = string_to_int(example, Tx, human_vocab)\n",
        "# source = np.array(list(map(lambda x: to_categorical(x, num_classes=len(human_vocab)), source))).swapaxes(0,1)\n",
        "# prediction = model.predict([sample, s0, c0])\n",
        "\n",
        "# model_path = '/content/drive/MyDrive/Data/DLNLP/dates_model.h5'\n",
        "# source = string_to_int(example, Tx, human_vocab)\n",
        "# source = np.array(list(map(lambda x: to_categorical(x, num_classes=len(human_vocab)), source))).swapaxes(0,1)\n",
        "\n",
        "# visualize_class_activation_map(model_path, [source, s0, c0])\n"
      ],
      "metadata": {
        "id": "CIUaUUWPB3s9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction = mod.predict([np.reshape(Xoh[0],(1,37,30)), s0, c0])"
      ],
      "metadata": {
        "id": "ayv_xmuQSi8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# source = np.reshape(source,(1,37,30))\n",
        "# source.shape"
      ],
      "metadata": {
        "id": "MeoRnvW5PsqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ouputs,alphas1 = mod.predict([source, s0, c0])"
      ],
      "metadata": {
        "id": "WW4-6WL-P0CI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EXAMPLES = ['3 May 1979', '5 April 09', '21th of August 2016', 'Tue 10 Jul 2007', 'Saturday May 9 2018', 'March 3 2001', 'March 3rd 2001', '1 March 2001']\n",
        "# for example in EXAMPLES:\n",
        "    \n",
        "#     source = string_to_int(example, Tx, human_vocab)\n",
        "#     source = np.array(list(map(lambda x: to_categorical(x, num_classes=len(human_vocab)), source))).swapaxes(0,1)\n",
        "#     prediction = mod.predict([source, s0, c0])\n",
        "#     prediction = np.argmax(prediction, axis = -1)\n",
        "#     output = [inv_machine_vocab[int(i)] for i in prediction]\n",
        "    \n",
        "#     print(\"source:\", example)\n",
        "#     print(\"output:\", ''.join(output))"
      ],
      "metadata": {
        "id": "nAN_mCZ1Q2Tn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "from keras import regularizers, constraints, initializers, activations\n",
        "from keras.layers.recurrent import Recurrent, _time_distributed_dense\n",
        "from keras.engine import InputSpec\n",
        "\n",
        "tfPrint = lambda d, T: tf.Print(input_=T, data=[T, tf.shape(T)], message=d)\n",
        "\n",
        "class AttentionDecoder(Recurrent):\n",
        "\n",
        "    def __init__(self, units, output_dim,\n",
        "                 activation='tanh',\n",
        "                 return_probabilities=False,\n",
        "                 name='AttentionDecoder',\n",
        "                 kernel_initializer='glorot_uniform',\n",
        "                 recurrent_initializer='orthogonal',\n",
        "                 bias_initializer='zeros',\n",
        "                 kernel_regularizer=None,\n",
        "                 bias_regularizer=None,\n",
        "                 activity_regularizer=None,\n",
        "                 kernel_constraint=None,\n",
        "                 bias_constraint=None,\n",
        "                 **kwargs):\n",
        "        \"\"\"\n",
        "        Implements an AttentionDecoder that takes in a sequence encoded by an\n",
        "        encoder and outputs the decoded states\n",
        "        :param units: dimension of the hidden state and the attention matrices\n",
        "        :param output_dim: the number of labels in the output space\n",
        "\n",
        "        references:\n",
        "            Bahdanau, Dzmitry, Kyunghyun Cho, and Yoshua Bengio.\n",
        "            \"Neural machine translation by jointly learning to align and translate.\"\n",
        "            arXiv preprint arXiv:1409.0473 (2014).\n",
        "        \"\"\"\n",
        "        self.units = units\n",
        "        self.output_dim = output_dim\n",
        "        self.return_probabilities = return_probabilities\n",
        "        self.activation = activations.get(activation)\n",
        "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
        "        self.recurrent_initializer = initializers.get(recurrent_initializer)\n",
        "        self.bias_initializer = initializers.get(bias_initializer)\n",
        "\n",
        "        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n",
        "        self.recurrent_regularizer = regularizers.get(kernel_regularizer)\n",
        "        self.bias_regularizer = regularizers.get(bias_regularizer)\n",
        "        self.activity_regularizer = regularizers.get(activity_regularizer)\n",
        "\n",
        "        self.kernel_constraint = constraints.get(kernel_constraint)\n",
        "        self.recurrent_constraint = constraints.get(kernel_constraint)\n",
        "        self.bias_constraint = constraints.get(bias_constraint)\n",
        "\n",
        "        super(AttentionDecoder, self).__init__(**kwargs)\n",
        "        self.name = name\n",
        "        self.return_sequences = True  # must return sequences\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        \"\"\"\n",
        "          See Appendix 2 of Bahdanau 2014, arXiv:1409.0473\n",
        "          for model details that correspond to the matrices here.\n",
        "        \"\"\"\n",
        "\n",
        "        self.batch_size, self.timesteps, self.input_dim = input_shape\n",
        "\n",
        "        if self.stateful:\n",
        "            super(AttentionDecoder, self).reset_states()\n",
        "\n",
        "        self.states = [None, None]  # y, s\n",
        "\n",
        "        \"\"\"\n",
        "            Matrices for creating the context vector\n",
        "        \"\"\"\n",
        "\n",
        "        self.V_a = self.add_weight(shape=(self.units,),\n",
        "                                   name='V_a',\n",
        "                                   initializer=self.kernel_initializer,\n",
        "                                   regularizer=self.kernel_regularizer,\n",
        "                                   constraint=self.kernel_constraint)\n",
        "        self.W_a = self.add_weight(shape=(self.units, self.units),\n",
        "                                   name='W_a',\n",
        "                                   initializer=self.kernel_initializer,\n",
        "                                   regularizer=self.kernel_regularizer,\n",
        "                                   constraint=self.kernel_constraint)\n",
        "        self.U_a = self.add_weight(shape=(self.input_dim, self.units),\n",
        "                                   name='U_a',\n",
        "                                   initializer=self.kernel_initializer,\n",
        "                                   regularizer=self.kernel_regularizer,\n",
        "                                   constraint=self.kernel_constraint)\n",
        "        self.b_a = self.add_weight(shape=(self.units,),\n",
        "                                   name='b_a',\n",
        "                                   initializer=self.bias_initializer,\n",
        "                                   regularizer=self.bias_regularizer,\n",
        "                                   constraint=self.bias_constraint)\n",
        "        \"\"\"\n",
        "            Matrices for the r (reset) gate\n",
        "        \"\"\"\n",
        "        self.C_r = self.add_weight(shape=(self.input_dim, self.units),\n",
        "                                   name='C_r',\n",
        "                                   initializer=self.recurrent_initializer,\n",
        "                                   regularizer=self.recurrent_regularizer,\n",
        "                                   constraint=self.recurrent_constraint)\n",
        "        self.U_r = self.add_weight(shape=(self.units, self.units),\n",
        "                                   name='U_r',\n",
        "                                   initializer=self.recurrent_initializer,\n",
        "                                   regularizer=self.recurrent_regularizer,\n",
        "                                   constraint=self.recurrent_constraint)\n",
        "        self.W_r = self.add_weight(shape=(self.output_dim, self.units),\n",
        "                                   name='W_r',\n",
        "                                   initializer=self.recurrent_initializer,\n",
        "                                   regularizer=self.recurrent_regularizer,\n",
        "                                   constraint=self.recurrent_constraint)\n",
        "        self.b_r = self.add_weight(shape=(self.units, ),\n",
        "                                   name='b_r',\n",
        "                                   initializer=self.bias_initializer,\n",
        "                                   regularizer=self.bias_regularizer,\n",
        "                                   constraint=self.bias_constraint)\n",
        "\n",
        "        \"\"\"\n",
        "            Matrices for the z (update) gate\n",
        "        \"\"\"\n",
        "        self.C_z = self.add_weight(shape=(self.input_dim, self.units),\n",
        "                                   name='C_z',\n",
        "                                   initializer=self.recurrent_initializer,\n",
        "                                   regularizer=self.recurrent_regularizer,\n",
        "                                   constraint=self.recurrent_constraint)\n",
        "        self.U_z = self.add_weight(shape=(self.units, self.units),\n",
        "                                   name='U_z',\n",
        "                                   initializer=self.recurrent_initializer,\n",
        "                                   regularizer=self.recurrent_regularizer,\n",
        "                                   constraint=self.recurrent_constraint)\n",
        "        self.W_z = self.add_weight(shape=(self.output_dim, self.units),\n",
        "                                   name='W_z',\n",
        "                                   initializer=self.recurrent_initializer,\n",
        "                                   regularizer=self.recurrent_regularizer,\n",
        "                                   constraint=self.recurrent_constraint)\n",
        "        self.b_z = self.add_weight(shape=(self.units, ),\n",
        "                                   name='b_z',\n",
        "                                   initializer=self.bias_initializer,\n",
        "                                   regularizer=self.bias_regularizer,\n",
        "                                   constraint=self.bias_constraint)\n",
        "        \"\"\"\n",
        "            Matrices for the proposal\n",
        "        \"\"\"\n",
        "        self.C_p = self.add_weight(shape=(self.input_dim, self.units),\n",
        "                                   name='C_p',\n",
        "                                   initializer=self.recurrent_initializer,\n",
        "                                   regularizer=self.recurrent_regularizer,\n",
        "                                   constraint=self.recurrent_constraint)\n",
        "        self.U_p = self.add_weight(shape=(self.units, self.units),\n",
        "                                   name='U_p',\n",
        "                                   initializer=self.recurrent_initializer,\n",
        "                                   regularizer=self.recurrent_regularizer,\n",
        "                                   constraint=self.recurrent_constraint)\n",
        "        self.W_p = self.add_weight(shape=(self.output_dim, self.units),\n",
        "                                   name='W_p',\n",
        "                                   initializer=self.recurrent_initializer,\n",
        "                                   regularizer=self.recurrent_regularizer,\n",
        "                                   constraint=self.recurrent_constraint)\n",
        "        self.b_p = self.add_weight(shape=(self.units, ),\n",
        "                                   name='b_p',\n",
        "                                   initializer=self.bias_initializer,\n",
        "                                   regularizer=self.bias_regularizer,\n",
        "                                   constraint=self.bias_constraint)\n",
        "        \"\"\"\n",
        "            Matrices for making the final prediction vector\n",
        "        \"\"\"\n",
        "        self.C_o = self.add_weight(shape=(self.input_dim, self.output_dim),\n",
        "                                   name='C_o',\n",
        "                                   initializer=self.recurrent_initializer,\n",
        "                                   regularizer=self.recurrent_regularizer,\n",
        "                                   constraint=self.recurrent_constraint)\n",
        "        self.U_o = self.add_weight(shape=(self.units, self.output_dim),\n",
        "                                   name='U_o',\n",
        "                                   initializer=self.recurrent_initializer,\n",
        "                                   regularizer=self.recurrent_regularizer,\n",
        "                                   constraint=self.recurrent_constraint)\n",
        "        self.W_o = self.add_weight(shape=(self.output_dim, self.output_dim),\n",
        "                                   name='W_o',\n",
        "                                   initializer=self.recurrent_initializer,\n",
        "                                   regularizer=self.recurrent_regularizer,\n",
        "                                   constraint=self.recurrent_constraint)\n",
        "        self.b_o = self.add_weight(shape=(self.output_dim, ),\n",
        "                                   name='b_o',\n",
        "                                   initializer=self.bias_initializer,\n",
        "                                   regularizer=self.bias_regularizer,\n",
        "                                   constraint=self.bias_constraint)\n",
        "\n",
        "        # For creating the initial state:\n",
        "        self.W_s = self.add_weight(shape=(self.input_dim, self.units),\n",
        "                                   name='W_s',\n",
        "                                   initializer=self.recurrent_initializer,\n",
        "                                   regularizer=self.recurrent_regularizer,\n",
        "                                   constraint=self.recurrent_constraint)\n",
        "\n",
        "        self.input_spec = [\n",
        "            InputSpec(shape=(self.batch_size, self.timesteps, self.input_dim))]\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, x):\n",
        "        # store the whole sequence so we can \"attend\" to it at each timestep\n",
        "        self.x_seq = x\n",
        "\n",
        "        # apply the a dense layer over the time dimension of the sequence\n",
        "        # do it here because it doesn't depend on any previous steps\n",
        "        # thefore we can save computation time:\n",
        "        self._uxpb = _time_distributed_dense(self.x_seq, self.U_a, b=self.b_a,\n",
        "                                             input_dim=self.input_dim,\n",
        "                                             timesteps=self.timesteps,\n",
        "                                             output_dim=self.units)\n",
        "\n",
        "        return super(AttentionDecoder, self).call(x)\n",
        "\n",
        "    def get_initial_state(self, inputs):\n",
        "        # apply the matrix on the first time step to get the initial s0.\n",
        "        s0 = activations.tanh(K.dot(inputs[:, 0], self.W_s))\n",
        "\n",
        "        # from keras.layers.recurrent to initialize a vector of (batchsize,\n",
        "        # output_dim)\n",
        "        y0 = K.zeros_like(inputs)  # (samples, timesteps, input_dims)\n",
        "        y0 = K.sum(y0, axis=(1, 2))  # (samples, )\n",
        "        y0 = K.expand_dims(y0)  # (samples, 1)\n",
        "        y0 = K.tile(y0, [1, self.output_dim])\n",
        "\n",
        "        return [y0, s0]\n",
        "\n",
        "    def step(self, x, states):\n",
        "\n",
        "        ytm, stm = states\n",
        "\n",
        "        # repeat the hidden state to the length of the sequence\n",
        "        _stm = K.repeat(stm, self.timesteps)\n",
        "\n",
        "        # now multiplty the weight matrix with the repeated hidden state\n",
        "        _Wxstm = K.dot(_stm, self.W_a)\n",
        "\n",
        "        # calculate the attention probabilities\n",
        "        # this relates how much other timesteps contributed to this one.\n",
        "        et = K.dot(activations.tanh(_Wxstm + self._uxpb),\n",
        "                   K.expand_dims(self.V_a))\n",
        "        at = K.exp(et)\n",
        "        at_sum = K.sum(at, axis=1)\n",
        "        at_sum_repeated = K.repeat(at_sum, self.timesteps)\n",
        "        at /= at_sum_repeated  # vector of size (batchsize, timesteps, 1)\n",
        "\n",
        "        # calculate the context vector\n",
        "        context = K.squeeze(K.batch_dot(at, self.x_seq, axes=1), axis=1)\n",
        "        # ~~~> calculate new hidden state\n",
        "        # first calculate the \"r\" gate:\n",
        "\n",
        "        rt = activations.sigmoid(\n",
        "            K.dot(ytm, self.W_r)\n",
        "            + K.dot(stm, self.U_r)\n",
        "            + K.dot(context, self.C_r)\n",
        "            + self.b_r)\n",
        "\n",
        "        # now calculate the \"z\" gate\n",
        "        zt = activations.sigmoid(\n",
        "            K.dot(ytm, self.W_z)\n",
        "            + K.dot(stm, self.U_z)\n",
        "            + K.dot(context, self.C_z)\n",
        "            + self.b_z)\n",
        "\n",
        "        # calculate the proposal hidden state:\n",
        "        s_tp = activations.tanh(\n",
        "            K.dot(ytm, self.W_p)\n",
        "            + K.dot((rt * stm), self.U_p)\n",
        "            + K.dot(context, self.C_p)\n",
        "            + self.b_p)\n",
        "\n",
        "        # new hidden state:\n",
        "        st = (1-zt)*stm + zt * s_tp\n",
        "\n",
        "        yt = activations.softmax(\n",
        "            K.dot(ytm, self.W_o)\n",
        "            + K.dot(stm, self.U_o)\n",
        "            + K.dot(context, self.C_o)\n",
        "            + self.b_o)\n",
        "\n",
        "        if self.return_probabilities:\n",
        "            return at, [yt, st]\n",
        "        else:\n",
        "            return yt, [yt, st]\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        \"\"\"\n",
        "            For Keras internal compatability checking\n",
        "        \"\"\"\n",
        "        if self.return_probabilities:\n",
        "            return (None, self.timesteps, self.timesteps)\n",
        "        else:\n",
        "            return (None, self.timesteps, self.output_dim)\n",
        "\n",
        "    def get_config(self):\n",
        "        \"\"\"\n",
        "            For rebuilding models on load time.\n",
        "        \"\"\"\n",
        "        config = {\n",
        "            'output_dim': self.output_dim,\n",
        "            'units': self.units,\n",
        "            'return_probabilities': self.return_probabilities\n",
        "        }\n",
        "        base_config = super(AttentionDecoder, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "OhzdtnGFWsoz",
        "outputId": "88bbdc7c-7d07-4db8-ebcd-ad7ec0cbae40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-204-33f21ab0ad10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mregularizers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitializers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecurrent\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRecurrent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_time_distributed_dense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInputSpec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'Recurrent' from 'keras.layers.recurrent' (/usr/local/lib/python3.7/dist-packages/keras/layers/recurrent.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    }
  ]
}